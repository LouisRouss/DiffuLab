# AdamW optimizer configuration
_target_: torch.optim.AdamW
_partial_: false
lr: 1e-4
weight_decay: 0.01
betas: [0.9, 0.999]
eps: 1e-8 